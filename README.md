### IRIS BIOMETRIC SYSTEM



## INDEX:

1. Introduction
2. Pre Processing
3. Iris Segmentation
4. Normalization
5. Feature Encoding
6. Matching
7. Results
8. Conclusion
9. References

## INTRODUCTION:

Identification of people is becoming more important day by day due to increasing network society. Biometrics is a branch of science which deals which the identification of human beings based on their physical characteristics and behavior.  Biometric system has been created on various physical characteristics like fingerprints, face, iris, retina, voice, hand geometry and many more.

Of these, Iris recognition is gaining more and more popularity because of its unique epigenetic pattern among people and also it remains stable through one&#39;s adult life.

- **IRIS RECOGNITION:**

The Iris is a thin, circular structure in the eye, responsible for controlling the diameter and size of the pupil and thus the amount of light reaching the retina.Due to the epigenetic nature of iris patterns, the two eyes of anindividual contain completely independent iris patterns, and identical twins possess uncorrelated iris patterns. Generalized iris recognition consists of image acquisition, iris segmentation and localization, feature extraction and feature comparison. It is the most correct biometric recognition system so it is called as king of biometrics.

In spite of these features iris recognition technique deals with challenges such as i) eyes are partially occluded by eyelids, eyelashes, and shadows, ii) iris scanners are relatively expensive, iii) sometimes they occluded by specular reflection etc. To test the system, the set of images used are from CASIA database.

- **RESEARCH:**

Several researchers have implemented various methods for segmentation and localising the iris. John Daugman has proposed one of the most practical and robust methodologies, constituting the basis of many functioning systems. He used integro-differential operator to find both the iris inner and outer boundaries for iris segmentation. Wildes proposed a gradient based binary edge map construction followed by circular Hough transform for iris segmentation.

1. **PRE PROCESSING:**

Pre-processing of the acquired iris image involves detection of specular reflections and this stage must remove these noise elements that can affect the feature extraction process. This is done using the matlab&#39;s imfill function which fills holes in the grey scale image. Gaussian Filter is applied which smoothes the image. Then canny edge detector is used which helps in the process of image segmentation.

                        G(x,y)=e−(x2+y2)(2∗σ2)2∗π∗σ2                        ---(1)

x, y are position coordinates and σ   is the standard deviation

1. **IRIS SEGMENTATION:**

The first stage of iris recognition is to isolate the actual iris region in a digital eye image. The iris region can be approximated by two circles, one or the iris/sclera boundary and another for the iris/pupil boundary.A number of algorithms have been developed for iris localization (or) segmentation. Two iris segmentation methods have been discussed here.

- **DAUGMAN&#39;S INTEGRO-DIFFERENTIAL OPERATOR:**

In order to localize an iris, Daugman proposed an Integro differential operator method. It assumes that the pupil and limbus are circular contours and operate as a circular edge detector. Detecting the upper and lower eyelids is also carried out using the Integro-differential operator by adjusting the contour search from circular to a designed arcuate shape. The Integro-differential operator is defined as:


∫r,x,y❑I(x,y)dxdy2πrmax(r,xp,yp)Gσ(r)∗∂∂r



Where   G: Gaussian function,

                I: image,

  R: radius,

  xp,yp: center.

The operator searches for the circular path where there is maximum change in pixel values, by varying the radius and centre _x_ and _y_ position of the circular contour. The operator is applied iteratively with the amount of smoothing progressively reduced in order to attain precise localization. Eyelids are localized in a similar manner, with the path of contour integration changed from circular to an arc.

- **HOUGH TRANSFORM:**

The Hough transform is a standard computer vision algorithm that can be used to determine the parameters of simple geometric objects, such as lines and circles, present in an image. The circular transform can be employed to deduce the radius and centre coordinates of the pupil and iris regions. Firstly, an edge map is generated by using canny edge detection with proper threshold. From the edge map, votes are cast in Hough space for the parameters of circles passing through each edge point. These parameters are the centre coordinates _xc_ and _yc_, and the radius _r_, which are able to define any circle according to the equation:

                        (x-xc )2 + (y-yc )2 = r2                       ---(3)

A maximum point in the Hough space will correspond to the radius and centre coordinates of the circle best defined by the edge points. To detect the upper and lower eyelids we make use of parabolic Hough transform. Parabola equation given by:

                (x-h)2 = 4p (y-k),         ---(4)

where focus is (h,k+p) and directrix is y = k-p

Before creating an edge map, gradients were biased in the vertical direction for the outer iris/sclera boundary, as suggested by Wildes _et al_. Vertical and horizontal gradients were weighted equally for the inner iris/pupil boundary.

1. **NORMALIZATION:**

Once the iris region is successfully segmented from an eye image, the next step is to transform the iris region so that it has fixed dimensions for doing the comparisons of templates. The dimensional variations between eye images are mostly due to the stretching of the iris caused by pupil dilation from varying levels of illumination. The normalization process produces iris regions, which have the same constant dimensions, so that two photographs of the same iris under different conditions will have characteristic features at the same spatial location.

- **DAUGMAN&#39;S RUBBER SHEET MODEL:**

The homogenous rubber sheet model devised by Daugman remaps each point within the iris region to a pair of polar coordinates (_r,θ_) where _r_ is on the interval [0,1] and _θ_ is angle [0,2π]. The remapping of the iris region from _(x,y)_ Cartesian coordinates to the normalized non-concentric polar representation which can be given as ,

        I(x(r,θ),y(r,θ))=I(r,θ)                           ---(5)

        x(r,θ)=(1−r)xp(θ)+rxl(θ)

        y(r,θ)=(1−r)yp(θ)+ryl(θ)

where        I: image,

xp ,yp and xl ,yl are the coordinates of the pupil and iris boundaries along the θdirection.

The rubber sheet model takes into account pupil dilation and size inconsistencies in order to produce a normalized representation with constant dimensions but it doesn&#39;t compensate for rotational inconsistencies. In the Daugman system, rotation is accounted for during matching by shifting the iris templates in the **θ** direction until two iris templates are aligned.



1. **FEATURE ENCODING:**

In order to provide accurate recognition of individuals, the most discriminating information present in an iris pattern must be extracted. Only the significant features of the iris must be encoded so that comparisons between templates can be made. The template that is generated in the feature encoding process will also need a corresponding matching metric, which gives a measure of similarity between two iris templates.

- **HAAR WAVELET:**

The basic Haar Wavelet is a piecewise constant function. In the Haar wavelet transformation method, low-pass filtering is conducted by averaging two adjacent pixel values, whereas the difference between two adjacent pixel values is figured out for high-pass filtering.The Haar wavelet applies a pair of low-pass and high-pass filters to image decomposition first in image columns and then in image rows independently. As a result, it produces four sub-bands LL1, LH1, HL1 and HH1 as the output of the first level Haar wavelet. The WT separates an image into a lower resolution approximation image (LL) as well as horizontal (HL), vertical (LH) and diagonal (HH) detail components. The process can then be repeated to compute multiple scale wavelet decomposition.





- **GABOR FILTERS:**

Gabor elementary functions are Gaussians modulated by sinusoidal functions. A two-dimensional (2D) even Gabor filter can be represented by the following equation in the spatial domain:

This is able to provide the optimum conjoint localization in both space and frequency, since a sine wave is perfectly localized in frequency, but not localized in space. Modulation of the sine with a Gaussian provides localization in space, though with loss of localization in frequency. Decomposition of a signal is accomplished using a quadrature pair of Gabor filters, with a real part specified by a cosine modulated by a Gaussian, and an imaginary part specified by a sine modulated by a Gaussian. It is done by quantizing the phase information into four levels, for each possible quadrant in the complex plane. These four levels are represented using two bits of data, so each pixel in the normalized iris pattern corresponds to two bits of data in the iris template.

- **TEMPLATE FORMATION:**

The template matching approach was used to provide higher accuracy in iris identification. The localized iris was divided into small blocks of 3\*10 sizes. In each block the mean gray level value was calculated. The quantization of gray level values was done on basis of previous mean value. If the mean showed increasing behavior then it was given a value 255 and if it showed decreasing behavior then it was quantized to value 128. However if the new mean falls out of range from previous value then it was assigned zero value. The templates generated were stored for further matching.



1. **MATCHING:**

The iris codes matching task is performed by pairing the iris codes extracted from the input and the template iris images. The most common comparison method of iris signatures is the Hamming Distance.

- **HAMMING DISTANCE:**

For matching, the Hamming distance was chosen as a metric for recognition, since bit-wise comparisons were necessary. The Hamming distance algorithm employed also incorporates noise masking, so that only significant bits are used in calculating the Hamming distance between two iris templates. Now when taking the Hamming distance, only those bits in the iris pattern that corresponds to &#39;0&#39; bits in noise masks of both iris patterns will be used in the calculation. The Hamming distance will be calculated using only the bits generated from the true iris region, and this modified Hamming distance formula is given as

  Although, in theory, two iris templates generated from the same iris will have a Hamming distance of 0.0, in practice this will not occur. Normalisation is not perfect, and also there will be some noise that goes undetected, so some variation will be present when comparing two intra-class iris templates. In order to account for rotational inconsistencies, when the Hamming distance of two templates is calculated, one template is shifted left and right bit- wise and a number of Hamming distance values are calculated from successive shifts.

**RESULTS:**

The project was tested on 400 images from CASIA Database. Then scaled version of these eyes (scale = 0.8) was used for identification.

321 images were identified correctly giving an accuracy of 80%.


**CONCLUSION:**

The goal of this project is to develop an iris recognition system by designing and implementing four subsystems, namely, localization, normalization, feature extraction, and matching. The goal was achieved as project achieved an accuracy of 80% , however accuracy can be improved by using better localization and feature extraction techniques.

**REFERENCES:**

1. Hannath C M and Shreeja R, &quot;A New Approach for Iris Recognition&quot;, International Journal of Computer Trends and Technology (IJCTT), Volume 4,Issue 7,July 2013
2. John Daugman, &quot;How Iris Recognition Works&quot;, IEEE Transactions on circuits and systems for video technology_,_ Volume 14, Issue 1, January 2004
3. Prateek Verma, Somak Basu and Praveen Verma &quot;Hough Transform Method for Iris Recognition-A Biometric Approach_&quot;,_International Journal of Engineering and Innovative Technology (IJEIT)_,_Volume 1, Issue 6, June 2012
4. Jinyu Zuo, Natalia Schmid and Xiaohan Chen &quot;On Generation and Analysis of Synthetic Iris Images_&quot;,_  IEEE Transactions on Information Forensics and Security_,_ Volume 2, Issue 1, March 2007
5. Wei Wei; Zhou Jun &quot;Image encryption algorithm Based on the key extracted from iris characteristics_&quot;,_  Computational Intelligence and Informatics (CINTI), 2013 IEEE 14th International Symposium on, Issue Date: 19-21 Nov. 2013
6. Libor Masek. &quot;Recognition of human iris patterns for biometric identification.&quot; Master&#39;s thesis, University of Western Australia,2003. Available from: \&lt;http://www.csse.uwa.edu.au/pk/studentprojects/libor/\&gt;.
